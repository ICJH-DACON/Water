{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.regression import setup, compare_models, blend_models,tune_model,predict_model,get_config, finalize_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'Gulim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.asia import SouthKorea\n",
    "import pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1039.0\n",
       "1        867.0\n",
       "2       1017.0\n",
       "3        978.0\n",
       "4        925.0\n",
       "         ...  \n",
       "1200    1093.0\n",
       "1201     832.0\n",
       "1202     579.0\n",
       "1203    1145.0\n",
       "1204    1015.0\n",
       "Name: 중식계, Length: 1205, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['중식계']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "- 일자에서 월과 일을 분리\n",
    "- 요일을 레이블 인코딩화(EDA로 요일의 중요도 순 파악)\n",
    "- 월 별, 일 별 중식 석식 수요 차이 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['월'] = pd.DatetimeIndex(train['일자']).month.astype(str)\n",
    "test['월'] = pd.DatetimeIndex(test['일자']).month.astype(str)\n",
    "train['주'] = pd.DatetimeIndex(train['일자']).week.astype(str)\n",
    "test['주'] = pd.DatetimeIndex(test['일자']).week.astype(str)\n",
    "train['일'] = pd.DatetimeIndex(train['일자']).day.astype(str)\n",
    "test['일'] = pd.DatetimeIndex(test['일자']).day.astype(str)\n",
    "\n",
    "train['출근'] = train['본사정원수']-(train['본사휴가자수']+train['본사출장자수']+train['현본사소속재택근무자수'])\n",
    "train['휴가비율'] = train['본사휴가자수']/train['본사정원수']\n",
    "train['출장비율'] = train['본사출장자수']/train['본사정원수']\n",
    "train['야근비율'] = train['본사시간외근무명령서승인건수']/train['출근']\n",
    "train['재택비율'] = train['현본사소속재택근무자수']/train['본사정원수']\n",
    "\n",
    "test['출근'] = test['본사정원수']-(test['본사휴가자수']+test['본사출장자수']+test['현본사소속재택근무자수'])\n",
    "test['휴가비율'] = test['본사휴가자수']/test['본사정원수']\n",
    "test['출장비율'] = test['본사출장자수']/test['본사정원수']\n",
    "test['야근비율'] = test['본사시간외근무명령서승인건수']/test['출근']\n",
    "test['재택비율'] = test['현본사소속재택근무자수']/test['본사정원수']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공휴일 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_holiday(date):\n",
    "    holidays = list(map(str, pd.Series(np.array(SouthKorea().holidays(int(date[:4])))[:, 0])))\n",
    "    \n",
    "    yesterday = str(np.datetime64(date) - 1)\n",
    "    tomorrow = str(np.datetime64(date) + 1)\n",
    "\n",
    "    if tomorrow in holidays and yesterday in holidays:\n",
    "        return 3 #'S'\n",
    "    if tomorrow in holidays:\n",
    "        return 2 # 'T'\n",
    "    elif yesterday in holidays:\n",
    "        return 1 #'Y'\n",
    "    else : \n",
    "        return 0 #'N'\n",
    "\n",
    "def week_of_month(x):\n",
    "    dt = pendulum.parse(x)\n",
    "    \n",
    "    wom = dt.week_of_month\n",
    "    if wom < 0:\n",
    "        wom += 52\n",
    "    return wom\n",
    "    \n",
    "\n",
    "df = pd.concat([train[['본사정원수', '일자']], test[['본사정원수', '일자']]])\n",
    "df['년월'] = df['일자'].apply(lambda x : x[:7])\n",
    "df = df[['년월', '본사정원수']].groupby(by=['년월'], as_index=False).mean()\n",
    "\n",
    "def member_change(date):\n",
    "    this_month = date[:7]\n",
    "    last_month = str(np.datetime64(this_month) - 1)\n",
    "    \n",
    "    this_month_member = int(df[df['년월'] == this_month]['본사정원수'])\n",
    "    last_month_member = int(df[df['년월'] == last_month]['본사정원수'])\n",
    "    \n",
    "    \n",
    "    return  this_month_member - last_month_member\n",
    "\n",
    "train['공휴일전후'] = train['일자'].apply(is_holiday)\n",
    "test['공휴일전후'] = test['일자'].apply(is_holiday)\n",
    "\n",
    "train['몇주차'] = train['일자'].apply(week_of_month)\n",
    "test['몇주차'] = test['일자'].apply(week_of_month)\n",
    "\n",
    "train = train[train['일자'] > '2016-03']\n",
    "train['인원변화'] = train['일자'].apply(member_change)\n",
    "test['인원변화'] = test['일자'].apply(member_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_rank4dinner = {\n",
    "    1: 11,\n",
    "    2: 2,\n",
    "    3: 1,\n",
    "    4: 4,\n",
    "    5: 7,\n",
    "    6: 6,\n",
    "    7: 10,\n",
    "    8: 8,\n",
    "    9: 5,\n",
    "    10: 3,\n",
    "    11: 9,\n",
    "    12: 12\n",
    "}\n",
    "train['월(석식)'] = train['월'].map(month_rank4dinner)\n",
    "test['월(석식)'] = test['월'].map(month_rank4dinner)\n",
    "\n",
    "month_rank4lunch = {\n",
    "    1: 3,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 6,\n",
    "    5: 7,\n",
    "    6: 8,\n",
    "    7: 10,\n",
    "    8: 9,\n",
    "    9: 5,\n",
    "    10: 4,\n",
    "    11: 11,\n",
    "    12: 12\n",
    "}\n",
    "train['월(중식)'] = train['월'].map(month_rank4lunch)\n",
    "test['월(중식)'] = test['월'].map(month_rank4lunch)\n",
    "\n",
    "weekday_rank4dinner = {\n",
    "    '월': 1,\n",
    "    '화': 2,\n",
    "    '수': 4,\n",
    "    '목': 3,\n",
    "    '금': 5,\n",
    "}\n",
    "\n",
    "weekday_rank4lunch = {\n",
    "    '월': 1,\n",
    "    '화': 2,\n",
    "    '수': 3,\n",
    "    '목': 4,\n",
    "    '금': 5,\n",
    "}\n",
    "\n",
    "rank = pd.DataFrame(range(1,53))\n",
    "week_rank_lunch = pd.pivot_table(train,values='중식계',index='주').sort_values(by='중식계').reset_index().drop('중식계',axis=1)\n",
    "week_rank_dinner = pd.pivot_table(train,values='석식계',index='주').sort_values(by='석식계').reset_index().drop('석식계',axis=1)\n",
    "\n",
    "\n",
    "week_rank4lunch = {}\n",
    "for i in range(len(rank)):\n",
    "    week_rank4lunch[week_rank_lunch['주'][i]] = rank[0][i]\n",
    "\n",
    "\n",
    "week_rank4dinner = {}\n",
    "for i in range(len(rank)):\n",
    "    week_rank4dinner[week_rank_dinner['주'][i]] = rank[0][i]\n",
    "    \n",
    "    \n",
    "train['주(중식)'] = train['주'].map(week_rank4lunch)\n",
    "test['주(중식)'] = test['주'].map(week_rank4lunch)\n",
    "\n",
    "train['주(석식)'] = train['주'].map(week_rank4dinner)\n",
    "test['주(석식)'] = test['주'].map(week_rank4dinner)\n",
    "\n",
    "train['요일(석식)'] = train['요일'].map(weekday_rank4dinner)\n",
    "test['요일(석식)'] = test['요일'].map(weekday_rank4dinner)\n",
    "\n",
    "train['요일(중식)'] = train['요일'].map(weekday_rank4lunch)\n",
    "test['요일(중식)'] = test['요일'].map(weekday_rank4lunch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 데이터 셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['일자', '요일', '본사정원수', '본사휴가자수', '본사출장자수', '본사시간외근무명령서승인건수',\n",
       "       '현본사소속재택근무자수', '조식메뉴', '중식메뉴', '석식메뉴', '중식계', '석식계', '월', '주', '일',\n",
       "       '출근', '휴가비율', '출장비율', '야근비율', '재택비율', '공휴일전후', '몇주차', '인원변화', '월(석식)',\n",
       "       '월(중식)', '주(중식)', '주(석식)', '요일(석식)', '요일(중식)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch_train = train.drop(columns=['본사정원수', '본사시간외근무명령서승인건수', '현본사소속재택근무자수','일자', '요일','주', '월', '석식계', '요일(석식)','조식메뉴', '중식메뉴', '석식메뉴','주(석식)', '월(석식)'])\n",
    "lunch_test = test.drop(columns=['본사정원수', '본사시간외근무명령서승인건수', '현본사소속재택근무자수','일자', '요일','주', '월', '요일(석식)', '월(석식)', '조식메뉴', '중식메뉴','주(석식)' , '석식메뉴'])\n",
    "\n",
    "\n",
    "dinner_train = train.drop(columns=['본사정원수', '본사시간외근무명령서승인건수', '현본사소속재택근무자수','일자', '요일','주', '월', '중식계', '요일(중식)','조식메뉴', '중식메뉴', '석식메뉴','주(중식)' , '월(중식)'])\n",
    "dinner_test = test.drop(columns=['본사정원수', '본사시간외근무명령서승인건수', '현본사소속재택근무자수','일자', '요일', '주','월', '요일(중식)', '월(중식)', '조식메뉴', '중식메뉴','주(중식)' , '석식메뉴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187, 15)\n",
      "(50, 14)\n"
     ]
    }
   ],
   "source": [
    "print(lunch_train.shape)\n",
    "print(lunch_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187, 15)\n",
      "(50, 14)\n"
     ]
    }
   ],
   "source": [
    "print(dinner_train.shape)\n",
    "print(dinner_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['본사휴가자수', '본사출장자수', '중식계', '일', '출근', '휴가비율', '출장비율', '야근비율', '재택비율',\n",
       "       '공휴일전후', '몇주차', '인원변화', '월(중식)', '주(중식)', '요일(중식)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunch_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분포 확인 및 분포 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>본사휴가자수</th>\n",
       "      <th>본사출장자수</th>\n",
       "      <th>석식계</th>\n",
       "      <th>일</th>\n",
       "      <th>출근</th>\n",
       "      <th>휴가비율</th>\n",
       "      <th>출장비율</th>\n",
       "      <th>야근비율</th>\n",
       "      <th>재택비율</th>\n",
       "      <th>공휴일전후</th>\n",
       "      <th>몇주차</th>\n",
       "      <th>인원변화</th>\n",
       "      <th>월(석식)</th>\n",
       "      <th>주(석식)</th>\n",
       "      <th>요일(석식)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>206</td>\n",
       "      <td>194</td>\n",
       "      <td>328.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2305.0</td>\n",
       "      <td>0.076155</td>\n",
       "      <td>0.071719</td>\n",
       "      <td>0.027332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>108</td>\n",
       "      <td>202</td>\n",
       "      <td>509.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2387.0</td>\n",
       "      <td>0.040044</td>\n",
       "      <td>0.074898</td>\n",
       "      <td>0.165899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>75</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2305.0</td>\n",
       "      <td>0.028495</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-65</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>55</td>\n",
       "      <td>222</td>\n",
       "      <td>647.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>0.020936</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.193191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>82</td>\n",
       "      <td>220</td>\n",
       "      <td>479.0</td>\n",
       "      <td>17</td>\n",
       "      <td>2324.0</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>0.186747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>164</td>\n",
       "      <td>302</td>\n",
       "      <td>462.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>0.062192</td>\n",
       "      <td>0.114524</td>\n",
       "      <td>0.027637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>59</td>\n",
       "      <td>256</td>\n",
       "      <td>575.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2333.0</td>\n",
       "      <td>0.022281</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.132447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>237</td>\n",
       "      <td>211</td>\n",
       "      <td>486.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>0.083480</td>\n",
       "      <td>0.074322</td>\n",
       "      <td>0.167712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>74</td>\n",
       "      <td>213</td>\n",
       "      <td>604.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.080529</td>\n",
       "      <td>0.205259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-194</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>70</td>\n",
       "      <td>265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>0.026495</td>\n",
       "      <td>0.100303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>63</td>\n",
       "      <td>290</td>\n",
       "      <td>503.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2292.0</td>\n",
       "      <td>0.023819</td>\n",
       "      <td>0.109641</td>\n",
       "      <td>0.103839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>53</td>\n",
       "      <td>304</td>\n",
       "      <td>469.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2287.0</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>0.114977</td>\n",
       "      <td>0.145606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>107</td>\n",
       "      <td>237</td>\n",
       "      <td>569.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>0.040469</td>\n",
       "      <td>0.089637</td>\n",
       "      <td>0.224783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>267</td>\n",
       "      <td>227</td>\n",
       "      <td>176.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>0.100188</td>\n",
       "      <td>0.085178</td>\n",
       "      <td>0.028558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>66</td>\n",
       "      <td>230</td>\n",
       "      <td>488.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>0.024859</td>\n",
       "      <td>0.086629</td>\n",
       "      <td>0.125901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>134</td>\n",
       "      <td>278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>0.049501</td>\n",
       "      <td>0.102697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>47</td>\n",
       "      <td>270</td>\n",
       "      <td>489.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2397.0</td>\n",
       "      <td>0.017318</td>\n",
       "      <td>0.099484</td>\n",
       "      <td>0.149771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>52</td>\n",
       "      <td>258</td>\n",
       "      <td>599.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2404.0</td>\n",
       "      <td>0.019160</td>\n",
       "      <td>0.095063</td>\n",
       "      <td>0.169717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>89</td>\n",
       "      <td>235</td>\n",
       "      <td>569.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2390.0</td>\n",
       "      <td>0.032793</td>\n",
       "      <td>0.086588</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>64</td>\n",
       "      <td>281</td>\n",
       "      <td>494.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>0.023521</td>\n",
       "      <td>0.103271</td>\n",
       "      <td>0.159512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>66</td>\n",
       "      <td>277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2385.0</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.101540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>224</td>\n",
       "      <td>223</td>\n",
       "      <td>515.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>0.082840</td>\n",
       "      <td>0.082470</td>\n",
       "      <td>0.151086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-24</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>168</td>\n",
       "      <td>237</td>\n",
       "      <td>629.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2591.0</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>0.079105</td>\n",
       "      <td>0.137013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>292</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>424</td>\n",
       "      <td>233</td>\n",
       "      <td>442.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>0.151159</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>0.100559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>89</td>\n",
       "      <td>300</td>\n",
       "      <td>449.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>0.031729</td>\n",
       "      <td>0.106952</td>\n",
       "      <td>0.085265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>107</td>\n",
       "      <td>215</td>\n",
       "      <td>476.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2493.0</td>\n",
       "      <td>0.038011</td>\n",
       "      <td>0.076377</td>\n",
       "      <td>0.179302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>894</td>\n",
       "      <td>159</td>\n",
       "      <td>104.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>0.314125</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.014501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>73</td>\n",
       "      <td>230</td>\n",
       "      <td>564.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.077052</td>\n",
       "      <td>0.162565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>254</td>\n",
       "      <td>271</td>\n",
       "      <td>464.0</td>\n",
       "      <td>28</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>0.090520</td>\n",
       "      <td>0.096579</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-179</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>83</td>\n",
       "      <td>252</td>\n",
       "      <td>541.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>0.029267</td>\n",
       "      <td>0.088858</td>\n",
       "      <td>0.209916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>109</td>\n",
       "      <td>253</td>\n",
       "      <td>494.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>0.038625</td>\n",
       "      <td>0.089653</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>60</td>\n",
       "      <td>272</td>\n",
       "      <td>405.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2493.0</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.096283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>67</td>\n",
       "      <td>265</td>\n",
       "      <td>472.0</td>\n",
       "      <td>25</td>\n",
       "      <td>2426.0</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>0.096084</td>\n",
       "      <td>0.236191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-67</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>223</td>\n",
       "      <td>218</td>\n",
       "      <td>503.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2319.0</td>\n",
       "      <td>0.080797</td>\n",
       "      <td>0.078986</td>\n",
       "      <td>0.188875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>118</td>\n",
       "      <td>266</td>\n",
       "      <td>516.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2921.0</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>0.080484</td>\n",
       "      <td>0.188292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>545</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>60</td>\n",
       "      <td>285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>2766.0</td>\n",
       "      <td>0.019286</td>\n",
       "      <td>0.091610</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-194</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>129</td>\n",
       "      <td>313</td>\n",
       "      <td>409.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>0.100288</td>\n",
       "      <td>0.153042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>170</td>\n",
       "      <td>235</td>\n",
       "      <td>609.0</td>\n",
       "      <td>25</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>0.054768</td>\n",
       "      <td>0.075709</td>\n",
       "      <td>0.271582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-17</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>343</td>\n",
       "      <td>228</td>\n",
       "      <td>124.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2540.0</td>\n",
       "      <td>0.110254</td>\n",
       "      <td>0.073288</td>\n",
       "      <td>0.051575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>101</td>\n",
       "      <td>214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>0.035803</td>\n",
       "      <td>0.075860</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-290</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>144</td>\n",
       "      <td>156</td>\n",
       "      <td>767.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2572.0</td>\n",
       "      <td>0.050139</td>\n",
       "      <td>0.054318</td>\n",
       "      <td>0.328927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>109</td>\n",
       "      <td>178</td>\n",
       "      <td>651.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>0.036949</td>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.288898</td>\n",
       "      <td>0.096610</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>248</td>\n",
       "      <td>153</td>\n",
       "      <td>327.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.082943</td>\n",
       "      <td>0.051171</td>\n",
       "      <td>0.233778</td>\n",
       "      <td>0.113378</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-31</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      본사휴가자수  본사출장자수    석식계   일      출근      휴가비율      출장비율      야근비율  \\\n",
       "222      206     194  328.0  26  2305.0  0.076155  0.071719  0.027332   \n",
       "242      108     202  509.0  23  2387.0  0.040044  0.074898  0.165899   \n",
       "262       75     252    0.0  22  2305.0  0.028495  0.095745  0.000000   \n",
       "280       55     222  647.0  21  2350.0  0.020936  0.084507  0.193191   \n",
       "299       82     220  479.0  17  2324.0  0.031226  0.083778  0.186747   \n",
       "324      164     302  462.0  26  2171.0  0.062192  0.114524  0.027637   \n",
       "345       59     256  575.0  27  2333.0  0.022281  0.096677  0.132447   \n",
       "364      237     211  486.0  24  2391.0  0.083480  0.074322  0.167712   \n",
       "384       74     213  604.0  22  2358.0  0.027977  0.080529  0.205259   \n",
       "410       70     265    0.0  27  2307.0  0.026495  0.100303  0.000000   \n",
       "428       63     290  503.0  31  2292.0  0.023819  0.109641  0.103839   \n",
       "430       53     304  469.0   2  2287.0  0.020045  0.114977  0.145606   \n",
       "442      107     237  569.0  20  2300.0  0.040469  0.089637  0.224783   \n",
       "467      267     227  176.0  26  2171.0  0.100188  0.085178  0.028558   \n",
       "486       66     230  488.0  23  2359.0  0.024859  0.086629  0.125901   \n",
       "510      134     278    0.0  28  2295.0  0.049501  0.102697  0.000000   \n",
       "520       47     270  489.0  15  2397.0  0.017318  0.099484  0.149771   \n",
       "528       52     258  599.0  27  2404.0  0.019160  0.095063  0.169717   \n",
       "547       89     235  569.0  23  2390.0  0.032793  0.086588  0.184100   \n",
       "567       64     281  494.0  24  2376.0  0.023521  0.103271  0.159512   \n",
       "589       66     277    0.0  27  2385.0  0.024194  0.101540  0.000000   \n",
       "607      224     223  515.0  23  2257.0  0.082840  0.082470  0.151086   \n",
       "627      168     237  629.0  21  2591.0  0.056075  0.079105  0.137013   \n",
       "651      424     233  442.0   8  2148.0  0.151159  0.083066  0.100559   \n",
       "666       89     300  449.0  30  2416.0  0.031729  0.106952  0.085265   \n",
       "685      107     215  476.0  26  2493.0  0.038011  0.076377  0.179302   \n",
       "705      894     159  104.0  24  1793.0  0.314125  0.055868  0.014501   \n",
       "724       73     230  564.0  22  2682.0  0.024456  0.077052  0.162565   \n",
       "748      254     271  464.0  28  2281.0  0.090520  0.096579  0.050855   \n",
       "765       83     252  541.0  26  2501.0  0.029267  0.088858  0.209916   \n",
       "784      109     253  494.0  22  2460.0  0.038625  0.089653  0.216667   \n",
       "804       60     272  405.0  22  2493.0  0.021239  0.096283  0.000000   \n",
       "827       67     265  472.0  25  2426.0  0.024293  0.096084  0.236191   \n",
       "846      223     218  503.0  22  2319.0  0.080797  0.078986  0.188875   \n",
       "871      118     266  516.0  27  2921.0  0.035703  0.080484  0.188292   \n",
       "890       60     285    0.0  25  2766.0  0.019286  0.091610  0.000362   \n",
       "908      129     313  409.0  24  2679.0  0.041333  0.100288  0.153042   \n",
       "930      170     235  609.0  25  2699.0  0.054768  0.075709  0.271582   \n",
       "950      343     228  124.0  23  2540.0  0.110254  0.073288  0.051575   \n",
       "973      101     214    0.0  29  2506.0  0.035803  0.075860  0.001596   \n",
       "991      144     156  767.0  24  2572.0  0.050139  0.054318  0.328927   \n",
       "1011     109     178  651.0  23  2378.0  0.036949  0.060339  0.288898   \n",
       "1184     248     153  327.0  21  2250.0  0.082943  0.051171  0.233778   \n",
       "\n",
       "          재택비율  공휴일전후  몇주차  인원변화  월(석식)  주(석식)  요일(석식)  \n",
       "222   0.000000      1    5    16     12      1       1  \n",
       "242   0.000000      0    5    -8     11      4       1  \n",
       "262   0.000000      0    4   -65      2     47       4  \n",
       "280   0.000000      0    4    -5      1     41       2  \n",
       "299   0.000000      0    4    -1      4     39       1  \n",
       "324   0.000000      0    4    11      7     28       5  \n",
       "345   0.000000      0    5    11      6      7       2  \n",
       "364   0.000000      0    5   191     10      6       1  \n",
       "384   0.000000      0    4  -194      8     46       2  \n",
       "410   0.000000      0    5    -3      5     16       4  \n",
       "428   0.000000      0    6     3      3     10       2  \n",
       "430   0.000000      0    1    -1      9     10       3  \n",
       "442   0.000000      0    4    -1      9     23       1  \n",
       "467   0.000000      1    5    21     12      1       2  \n",
       "486   0.000000      0    4   -10     11      4       2  \n",
       "510   0.000000      2    5    52      2     36       4  \n",
       "520   0.000000      0    3     7      1     49       3  \n",
       "528   0.000000      0    5     7      1     38       2  \n",
       "547   0.000000      0    5     0      4     13       1  \n",
       "567   0.000000      0    4     7      7     28       3  \n",
       "589   0.000000      0    5     7      6      7       4  \n",
       "607   0.000000      0    5   -24     10      6       1  \n",
       "627   0.000000      0    4   292      8     46       2  \n",
       "651   0.000000      2    2    42      3     50       1  \n",
       "666   0.000000      0    5    42      3     10       2  \n",
       "685   0.000000      0    5    10      9      5       1  \n",
       "705   0.000000      2    5    31     12      1       1  \n",
       "724   0.000000      0    4   139     11      4       2  \n",
       "748   0.000000      2    5  -179      2     36       3  \n",
       "765   0.000000      0    5    30      1     38       2  \n",
       "784   0.000000      0    4   -14      4     13       1  \n",
       "804   0.000000      0    4     3      7     28       4  \n",
       "827   0.000000      0    5   -67      6      7       2  \n",
       "846   0.000000      0    4     2     10      6       1  \n",
       "871   0.000000      0    5   545      8     24       2  \n",
       "890   0.000000      0    5  -194      5     16       4  \n",
       "908   0.000000      0    4    10      3      9       3  \n",
       "930   0.000000      0    5   -17      9      5       1  \n",
       "950   0.000000      0    5     7     12      1       1  \n",
       "973   0.000000      0    5  -290     11     19       4  \n",
       "991   0.000000      0    5    51      2     36       1  \n",
       "1011  0.096610      0    5    78      1     38       1  \n",
       "1184  0.113378      0    4   -31     12      1       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_index = dinner_train[dinner_train['석식계']==0].index\n",
    "\n",
    "dinner_train.iloc[drop_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1144, 15)\n"
     ]
    }
   ],
   "source": [
    "dinner_train.drop(drop_index, inplace=True)\n",
    "\n",
    "print(dinner_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중식 예측모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lunch = np.array(lunch_train['중식계'])\n",
    "y_lunch = y_lunch.reshape(-1)\n",
    "lunch_train.drop(columns=['중식계'], inplace=True)\n",
    "\n",
    "y_dinner = np.array(dinner_train['석식계'])\n",
    "y_dinner = y_dinner.reshape(-1)\n",
    "dinner_train.drop(columns=['석식계'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat features are: []\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cat_features = [f for f in lunch_train.columns if lunch_train[f].dtype == 'object']\n",
    "\n",
    "def column_index(df, cat_features):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols, cat_features, sorter=sidx)]\n",
    "\n",
    "cat_features_idx = column_index(lunch_train, cat_features)    \n",
    "print(\"Cat features are: %s\" % [f for f in cat_features])\n",
    "print(cat_features_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 168.5922245\ttest: 168.5922245\ttest1: 138.3824152\tbest: 138.3824152 (0)\ttotal: 153ms\tremaining: 7m 39s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 72.03514707\n",
      "bestIteration = 268\n",
      "\n",
      "Shrink model to first 269 iterations.\n",
      "[22:56:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:642.07739\tvalidation_1-rmse:684.34882\n",
      "[76]\tvalidation_0-rmse:12.58645\tvalidation_1-rmse:94.19297\n",
      "0:\tlearn: 164.6791609\ttest: 164.6791609\ttest1: 166.7869789\tbest: 166.7869789 (0)\ttotal: 2.9ms\tremaining: 8.71s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 71.22463855\n",
      "bestIteration = 306\n",
      "\n",
      "Shrink model to first 307 iterations.\n",
      "[22:56:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:641.28845\tvalidation_1-rmse:692.40070\n",
      "[68]\tvalidation_0-rmse:14.49809\tvalidation_1-rmse:91.62282\n",
      "0:\tlearn: 168.2375810\ttest: 168.2375810\ttest1: 138.2523481\tbest: 138.2523481 (0)\ttotal: 7.83ms\tremaining: 23.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 51.74402429\n",
      "bestIteration = 114\n",
      "\n",
      "Shrink model to first 115 iterations.\n",
      "[22:56:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:647.96832\tvalidation_1-rmse:632.09967\n",
      "[66]\tvalidation_0-rmse:16.00209\tvalidation_1-rmse:76.76378\n",
      "0:\tlearn: 163.3842917\ttest: 163.3842917\ttest1: 174.8629045\tbest: 174.8629045 (0)\ttotal: 2.59ms\tremaining: 7.78s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 75.01020632\n",
      "bestIteration = 318\n",
      "\n",
      "Shrink model to first 319 iterations.\n",
      "[22:56:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:644.39111\tvalidation_1-rmse:662.82672\n",
      "[74]\tvalidation_0-rmse:12.86856\tvalidation_1-rmse:103.74390\n",
      "0:\tlearn: 163.6449943\ttest: 163.6449943\ttest1: 172.3283775\tbest: 172.3283775 (0)\ttotal: 16ms\tremaining: 48s\n",
      "400:\tlearn: 44.5634679\ttest: 44.5634679\ttest1: 70.9632727\tbest: 70.8794508 (354)\ttotal: 618ms\tremaining: 4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 70.63584841\n",
      "bestIteration = 468\n",
      "\n",
      "Shrink model to first 469 iterations.\n",
      "[22:56:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:647.27032\tvalidation_1-rmse:633.63892\n",
      "[77]\tvalidation_0-rmse:12.72540\tvalidation_1-rmse:103.77537\n",
      "0:\tlearn: 164.2012214\ttest: 164.2012214\ttest1: 169.5752018\tbest: 169.5752018 (0)\ttotal: 3.51ms\tremaining: 10.5s\n",
      "400:\tlearn: 43.4225918\ttest: 43.4225918\ttest1: 71.7912171\tbest: 71.7147226 (386)\ttotal: 573ms\tremaining: 3.71s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 71.48390835\n",
      "bestIteration = 466\n",
      "\n",
      "Shrink model to first 467 iterations.\n",
      "[22:56:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:649.51501\tvalidation_1-rmse:607.76099\n",
      "[70]\tvalidation_0-rmse:11.72422\tvalidation_1-rmse:107.32616\n",
      "0:\tlearn: 162.4141954\ttest: 162.4141954\ttest1: 180.0700666\tbest: 180.0700666 (0)\ttotal: 18.3ms\tremaining: 54.8s\n",
      "400:\tlearn: 43.0035409\ttest: 43.0035409\ttest1: 87.5829946\tbest: 87.3559513 (365)\ttotal: 583ms\tremaining: 3.78s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 86.65023534\n",
      "bestIteration = 545\n",
      "\n",
      "Shrink model to first 546 iterations.\n",
      "[22:56:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:649.36340\tvalidation_1-rmse:605.23938\n",
      "[57]\tvalidation_0-rmse:17.30919\tvalidation_1-rmse:125.56937\n",
      "0:\tlearn: 161.8254081\ttest: 161.8254081\ttest1: 185.2110801\tbest: 185.2110801 (0)\ttotal: 3.79ms\tremaining: 11.4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 89.46642014\n",
      "bestIteration = 196\n",
      "\n",
      "Shrink model to first 197 iterations.\n",
      "[22:56:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:645.55200\tvalidation_1-rmse:650.63989\n",
      "[60]\tvalidation_0-rmse:15.34143\tvalidation_1-rmse:120.65151\n"
     ]
    }
   ],
   "source": [
    "n_fold = 8\n",
    "\n",
    "kfold = KFold(n_splits=n_fold, shuffle=False)\n",
    "# for each fold\n",
    "\n",
    "lunch_models_cat = [CatBoostRegressor(n_estimators = 3000, loss_function='MAE') for _ in range(n_fold)]\n",
    "lunch_preds_cat = []\n",
    "\n",
    "lunch_models_lgb = [GradientBoostingRegressor() for _ in range(n_fold)]\n",
    "lunch_preds_lgb = []\n",
    "\n",
    "lunch_trues = []\n",
    "\n",
    "for idx, (tr_idx, val_idx) in enumerate(kfold.split(lunch_train, y_lunch)):\n",
    "    X_tr, X_val = lunch_train.iloc[tr_idx], lunch_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_lunch[tr_idx], y_lunch[val_idx]\n",
    "\n",
    "    temp_model_cat = lunch_models_cat[idx]\n",
    "    temp_model_cat.fit(X_tr, y_tr,\n",
    "                   eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose=400)\n",
    "    \n",
    "    lunch_models_cat[idx] = temp_model_cat\n",
    "    \n",
    "    pred_cat = temp_model_cat.predict(X_val)\n",
    "    lunch_preds_cat.extend(pred_cat)\n",
    "\n",
    "    temp_model_xgb = lunch_models_xgb[idx]\n",
    "    temp_model_xgb.fit(X_tr, y_tr,\n",
    "                   eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose=400)\n",
    "    \n",
    "    lunch_models_xgb[idx] = temp_model_xgb\n",
    "    \n",
    "    pred_xgb = temp_model_xgb.predict(X_val)\n",
    "    lunch_preds_xgb.extend(pred_xgb)\n",
    "\n",
    "    temp_model_lgb = lunch_models_lgb[idx]\n",
    "    temp_model_lgb.fit(X_tr, y_tr)\n",
    "#                    eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "#                    early_stopping_rounds=50,\n",
    "#                    verbose=400)\n",
    "    \n",
    "    lunch_models_lgb[idx] = temp_model_lgb\n",
    "    \n",
    "    pred_lgb = temp_model_lgb.predict(X_val)\n",
    "    \n",
    "    lunch_preds_lgb.extend(pred_lgb)\n",
    "    \n",
    "    true = y_val\n",
    "    lunch_trues.extend(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73.50974592215007, 74.38434449784778, 72.24054512042277)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunch_preds_cat = np.array(lunch_preds_cat)\n",
    "lunch_preds_xgb = np.array(lunch_preds_xgb)\n",
    "lunch_preds_lgb = np.array(lunch_preds_lgb)\n",
    "\n",
    "lunch_trues = np.array(lunch_trues)\n",
    "\n",
    "abs(lunch_trues-lunch_preds_cat).mean(), abs(lunch_trues-lunch_preds_xgb).mean(), abs(lunch_trues-lunch_preds_lgb).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch = np.array([0]*50).astype(np.float64)\n",
    "\n",
    "for model in lunch_models_cat:\n",
    "    lunch += model.predict(lunch_test)\n",
    "    \n",
    "for model in lunch_models_xgb:\n",
    "    lunch += model.predict(lunch_test)\n",
    "    \n",
    "for model in lunch_models_lgb:\n",
    "    lunch += model.predict(lunch_test)\n",
    "    \n",
    "lunch /= n_fold * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 석식 예측모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 85.2238052\ttest: 85.2238052\ttest1: 68.5727962\tbest: 68.5727962 (0)\ttotal: 17.8ms\tremaining: 53.4s\n",
      "400:\tlearn: 28.8397855\ttest: 28.8397855\ttest1: 54.7475111\tbest: 54.7411145 (398)\ttotal: 700ms\tremaining: 4.53s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 53.71222229\n",
      "bestIteration = 591\n",
      "\n",
      "Shrink model to first 592 iterations.\n",
      "[22:56:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:343.15808\tvalidation_1-rmse:392.19907\n",
      "[69]\tvalidation_0-rmse:6.99724\tvalidation_1-rmse:67.21325\n",
      "0:\tlearn: 83.5292398\ttest: 83.5292398\ttest1: 76.2151039\tbest: 76.2151039 (0)\ttotal: 14.8ms\tremaining: 44.3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 52.43327422\n",
      "bestIteration = 297\n",
      "\n",
      "Shrink model to first 298 iterations.\n",
      "[22:56:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:344.87405\tvalidation_1-rmse:373.62537\n",
      "[74]\tvalidation_0-rmse:6.56477\tvalidation_1-rmse:71.33611\n",
      "0:\tlearn: 85.6619571\ttest: 85.6619571\ttest1: 61.3648242\tbest: 61.3648242 (0)\ttotal: 11.2ms\tremaining: 33.6s\n",
      "400:\tlearn: 29.5411815\ttest: 29.5411815\ttest1: 36.6457094\tbest: 36.5739300 (361)\ttotal: 586ms\tremaining: 3.79s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 36.57393001\n",
      "bestIteration = 361\n",
      "\n",
      "Shrink model to first 362 iterations.\n",
      "[22:56:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:348.71320\tvalidation_1-rmse:341.37097\n",
      "[60]\tvalidation_0-rmse:10.30717\tvalidation_1-rmse:51.73064\n",
      "0:\tlearn: 84.2424666\ttest: 84.2424666\ttest1: 70.9278312\tbest: 70.9278312 (0)\ttotal: 2.5ms\tremaining: 7.49s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 40.09873494\n",
      "bestIteration = 279\n",
      "\n",
      "Shrink model to first 280 iterations.\n",
      "[22:56:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:346.97632\tvalidation_1-rmse:355.63858\n",
      "[60]\tvalidation_0-rmse:9.60324\tvalidation_1-rmse:61.19418\n",
      "0:\tlearn: 82.8244246\ttest: 82.8244246\ttest1: 81.4742648\tbest: 81.4742648 (0)\ttotal: 3.45ms\tremaining: 10.4s\n",
      "400:\tlearn: 28.8815370\ttest: 28.8815370\ttest1: 47.8426278\tbest: 47.7876503 (399)\ttotal: 624ms\tremaining: 4.05s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 47.78141444\n",
      "bestIteration = 405\n",
      "\n",
      "Shrink model to first 406 iterations.\n",
      "[22:56:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:346.93872\tvalidation_1-rmse:358.91769\n",
      "[72]\tvalidation_0-rmse:6.78267\tvalidation_1-rmse:69.19962\n",
      "0:\tlearn: 83.3610180\ttest: 83.3610180\ttest1: 77.8113277\tbest: 77.8113277 (0)\ttotal: 3.76ms\tremaining: 11.3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 43.57543909\n",
      "bestIteration = 150\n",
      "\n",
      "Shrink model to first 151 iterations.\n",
      "[22:56:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:348.76044\tvalidation_1-rmse:335.91659\n",
      "[60]\tvalidation_0-rmse:10.96353\tvalidation_1-rmse:68.75431\n",
      "0:\tlearn: 78.0890500\ttest: 78.0890500\ttest1: 115.2363627\tbest: 115.2363627 (0)\ttotal: 17.3ms\tremaining: 51.7s\n",
      "400:\tlearn: 28.2189896\ttest: 28.2189896\ttest1: 59.2269124\tbest: 59.2267045 (399)\ttotal: 560ms\tremaining: 3.63s\n",
      "800:\tlearn: 21.1367106\ttest: 21.1367106\ttest1: 56.5228541\tbest: 56.5228541 (800)\ttotal: 1.13s\tremaining: 3.11s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 56.42867598\n",
      "bestIteration = 857\n",
      "\n",
      "Shrink model to first 858 iterations.\n",
      "[22:56:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:349.84506\tvalidation_1-rmse:327.41022\n",
      "[59]\tvalidation_0-rmse:10.13303\tvalidation_1-rmse:81.97323\n",
      "0:\tlearn: 77.0716374\ttest: 77.0716374\ttest1: 124.0321668\tbest: 124.0321668 (0)\ttotal: 13.3ms\tremaining: 39.9s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 68.50806951\n",
      "bestIteration = 265\n",
      "\n",
      "Shrink model to first 266 iterations.\n",
      "[22:56:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"loss_function\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-rmse:353.13312\tvalidation_1-rmse:288.59186\n",
      "[58]\tvalidation_0-rmse:10.88458\tvalidation_1-rmse:88.73614\n"
     ]
    }
   ],
   "source": [
    "dinner_models_cat = [CatBoostRegressor(n_estimators = 3000, loss_function='MAE') for _ in range(n_fold)]\n",
    "dinner_preds_cat = []\n",
    "\n",
    "dinner_models_xgb = [XGBRegressor(n_estimators = 3000, loss_function='MAE') for _ in range(n_fold)]\n",
    "dinner_preds_xgb = []\n",
    "\n",
    "dinner_models_lgb = [GradientBoostingRegressor() for _ in range(n_fold)]\n",
    "dinner_preds_lgb = []\n",
    "\n",
    "dinner_trues = []\n",
    "\n",
    "for idx, (tr_idx, val_idx) in enumerate(kfold.split(dinner_train, y_dinner)):\n",
    "    X_tr, X_val = dinner_train.iloc[tr_idx], dinner_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_dinner[tr_idx], y_dinner[val_idx]\n",
    "\n",
    "    temp_model_cat = dinner_models_cat[idx]\n",
    "    temp_model_cat.fit(X_tr, y_tr,\n",
    "                   eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose=400)\n",
    "    \n",
    "    dinner_models_cat[idx] = temp_model_cat\n",
    "    \n",
    "    pred_cat = temp_model_cat.predict(X_val)\n",
    "    dinner_preds_cat.extend(pred_cat)\n",
    "\n",
    "    temp_model_xgb = dinner_models_xgb[idx]\n",
    "    temp_model_xgb.fit(X_tr, y_tr,\n",
    "                   eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "                   early_stopping_rounds=50,\n",
    "                   verbose=400)\n",
    "    \n",
    "    dinner_models_xgb[idx] = temp_model_xgb\n",
    "    \n",
    "    pred_xgb = temp_model_xgb.predict(X_val)\n",
    "    dinner_preds_xgb.extend(pred_xgb)\n",
    "\n",
    "    temp_model_lgb = dinner_models_lgb[idx]\n",
    "    temp_model_lgb.fit(X_tr, y_tr)\n",
    "#                    eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "#                    early_stopping_rounds=50,\n",
    "#                    verbose=400)\n",
    "    \n",
    "    dinner_models_lgb[idx] = temp_model_lgb\n",
    "    \n",
    "    pred_lgb = temp_model_lgb.predict(X_val)\n",
    "    \n",
    "    dinner_preds_lgb.extend(pred_lgb)\n",
    "    \n",
    "    true = y_val\n",
    "    dinner_trues.extend(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.88897106040549, 51.57074193354253, 49.92871998816373)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinner_preds_cat = np.array(dinner_preds_cat)\n",
    "dinner_preds_xgb = np.array(dinner_preds_xgb)\n",
    "dinner_preds_lgb = np.array(dinner_preds_lgb)\n",
    "\n",
    "dinner_trues = np.array(dinner_trues)\n",
    "\n",
    "abs(dinner_trues-dinner_preds_cat).mean(), abs(dinner_trues-dinner_preds_xgb).mean(), abs(dinner_trues-dinner_preds_lgb).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "singles = set()\n",
    "for idx, model in enumerate(dinner_models_xgb):\n",
    "    singles.add((f'model_{idx}', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinner = np.array([0]*50).astype(np.float64)\n",
    "\n",
    "for model in dinner_models_cat:\n",
    "    dinner += model.predict(dinner_test)\n",
    "    \n",
    "for model in dinner_models_xgb:\n",
    "    dinner += model.predict(dinner_test)\n",
    "    \n",
    "for model in dinner_models_lgb:\n",
    "    dinner += model.predict(dinner_test)\n",
    "    \n",
    "dinner /= n_fold * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>중식계</th>\n",
       "      <th>석식계</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>997.386078</td>\n",
       "      <td>394.749940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>917.563183</td>\n",
       "      <td>423.263700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>633.809321</td>\n",
       "      <td>265.606942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>1266.491530</td>\n",
       "      <td>528.036139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>1053.239421</td>\n",
       "      <td>477.726098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           일자          중식계         석식계\n",
       "0  2021-01-27   997.386078  394.749940\n",
       "1  2021-01-28   917.563183  423.263700\n",
       "2  2021-01-29   633.809321  265.606942\n",
       "3  2021-02-01  1266.491530  528.036139\n",
       "4  2021-02-02  1053.239421  477.726098"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission.iloc[:,1] = lunch\n",
    "submission.iloc[:,2] = dinner\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.046823470703345, 22.249960691412088)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = pd.read_csv('../submission/제출해야될것.csv')\n",
    "\n",
    "lunch_answer = np.array(answer.iloc[:,1])\n",
    "dinner_answer = np.array(answer.iloc[:,2])\n",
    "\n",
    "abs(lunch - lunch_answer).mean(), abs(dinner - dinner_answer).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>중식계</th>\n",
       "      <th>석식계</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>997.386078</td>\n",
       "      <td>394.749940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>917.563183</td>\n",
       "      <td>423.263700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>633.809321</td>\n",
       "      <td>265.606942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>1266.491530</td>\n",
       "      <td>528.036139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>1053.239421</td>\n",
       "      <td>477.726098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>1007.581626</td>\n",
       "      <td>441.438999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>949.280661</td>\n",
       "      <td>451.682368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>691.828846</td>\n",
       "      <td>374.403599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>1278.054235</td>\n",
       "      <td>618.737977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-02-09</td>\n",
       "      <td>1067.367825</td>\n",
       "      <td>552.539965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>853.116739</td>\n",
       "      <td>277.588616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            일자          중식계         석식계\n",
       "0   2021-01-27   997.386078  394.749940\n",
       "1   2021-01-28   917.563183  423.263700\n",
       "2   2021-01-29   633.809321  265.606942\n",
       "3   2021-02-01  1266.491530  528.036139\n",
       "4   2021-02-02  1053.239421  477.726098\n",
       "5   2021-02-03  1007.581626  441.438999\n",
       "6   2021-02-04   949.280661  451.682368\n",
       "7   2021-02-05   691.828846  374.403599\n",
       "8   2021-02-08  1278.054235  618.737977\n",
       "9   2021-02-09  1067.367825  552.539965\n",
       "10  2021-02-10   853.116739  277.588616"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날짜 : 20210628\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.datetime.now().date()).replace(\"-\",\"\")\n",
    "print(\"오늘 날짜 : \" + today)\n",
    "\n",
    "submission.to_csv(f'../submission/{today}_cat_xgb_8.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names, model_type):\n",
    "    \n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dinner_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-314bf8f48a65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mplot_feature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdinner_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdinner_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"CATBOOST\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dinner_models' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(n_fold):\n",
    "    plot_feature_importance(dinner_models[0].get_feature_importance(),dinner_train.iloc[:,:-1].columns,\"CATBOOST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
