{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.regression import setup, compare_models, blend_models,tune_model,predict_model,get_config, finalize_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'Gulim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.asia import SouthKorea\n",
    "import pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식계']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "- 일자에서 월과 일을 분리\n",
    "- 요일을 레이블 인코딩화(EDA로 요일의 중요도 순 파악)\n",
    "- 월 별, 일 별 중식 석식 수요 차이 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['월'] = pd.DatetimeIndex(train['일자']).month.astype(int)\n",
    "test['월'] = pd.DatetimeIndex(test['일자']).month.astype(int)\n",
    "train['주'] = pd.DatetimeIndex(train['일자']).week.astype(int)\n",
    "test['주'] = pd.DatetimeIndex(test['일자']).week.astype(int)\n",
    "train['일'] = pd.DatetimeIndex(train['일자']).day.astype(int)\n",
    "test['일'] = pd.DatetimeIndex(test['일자']).day.astype(int)\n",
    "\n",
    "train['출근'] = train['본사정원수']-(train['본사휴가자수']+train['본사출장자수']+train['현본사소속재택근무자수'])\n",
    "train['휴가비율'] = train['본사휴가자수']/train['본사정원수']\n",
    "train['출장비율'] = train['본사출장자수']/train['본사정원수']\n",
    "train['야근비율'] = train['본사시간외근무명령서승인건수']/train['출근']\n",
    "train['재택비율'] = train['현본사소속재택근무자수']/train['본사정원수']\n",
    "\n",
    "test['출근'] = test['본사정원수']-(test['본사휴가자수']+test['본사출장자수']+test['현본사소속재택근무자수'])\n",
    "test['휴가비율'] = test['본사휴가자수']/test['본사정원수']\n",
    "test['출장비율'] = test['본사출장자수']/test['본사정원수']\n",
    "test['야근비율'] = test['본사시간외근무명령서승인건수']/test['출근']\n",
    "test['재택비율'] = test['현본사소속재택근무자수']/test['본사정원수']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공휴일 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_holiday(date):\n",
    "    holidays = list(map(str, pd.Series(np.array(SouthKorea().holidays(int(date[:4])))[:, 0])))\n",
    "    \n",
    "    yesterday = str(np.datetime64(date) - 1)\n",
    "    tomorrow = str(np.datetime64(date) + 1)\n",
    "\n",
    "    if tomorrow in holidays and yesterday in holidays:\n",
    "        return 3 #'S'\n",
    "    if tomorrow in holidays:\n",
    "        return 2 # 'T'\n",
    "    elif yesterday in holidays:\n",
    "        return 1 #'Y'\n",
    "    else : \n",
    "        return 0 #'N'\n",
    "\n",
    "def week_of_month(x):\n",
    "    dt = pendulum.parse(x)\n",
    "    \n",
    "    wom = dt.week_of_month\n",
    "    if wom < 0:\n",
    "        wom += 52\n",
    "    return wom\n",
    "    \n",
    "\n",
    "df = pd.concat([train[['본사정원수', '일자']], test[['본사정원수', '일자']]])\n",
    "df['년월'] = df['일자'].apply(lambda x : x[:7])\n",
    "df = df[['년월', '본사정원수']].groupby(by=['년월'], as_index=False).mean()\n",
    "\n",
    "def member_change(date):\n",
    "    this_month = date[:7]\n",
    "    last_month = str(np.datetime64(this_month) - 1)\n",
    "    \n",
    "    this_month_member = int(df[df['년월'] == this_month]['본사정원수'])\n",
    "    last_month_member = int(df[df['년월'] == last_month]['본사정원수'])\n",
    "    \n",
    "    \n",
    "    return  this_month_member - last_month_member\n",
    "\n",
    "train['공휴일전후'] = train['일자'].apply(is_holiday)\n",
    "test['공휴일전후'] = test['일자'].apply(is_holiday)\n",
    "\n",
    "train['몇주차'] = train['일자'].apply(week_of_month)\n",
    "test['몇주차'] = test['일자'].apply(week_of_month)\n",
    "\n",
    "train = train[train['일자'] > '2016-03']\n",
    "train['인원변화'] = train['일자'].apply(member_change)\n",
    "test['인원변화'] = test['일자'].apply(member_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_rank4dinner = {\n",
    "    1: 11,\n",
    "    2: 2,\n",
    "    3: 1,\n",
    "    4: 4,\n",
    "    5: 7,\n",
    "    6: 6,\n",
    "    7: 10,\n",
    "    8: 8,\n",
    "    9: 5,\n",
    "    10: 3,\n",
    "    11: 9,\n",
    "    12: 12\n",
    "}\n",
    "train['월(석식)'] = train['월'].map(month_rank4dinner)\n",
    "test['월(석식)'] = test['월'].map(month_rank4dinner)\n",
    "\n",
    "month_rank4lunch = {\n",
    "    1: 3,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 6,\n",
    "    5: 7,\n",
    "    6: 8,\n",
    "    7: 10,\n",
    "    8: 9,\n",
    "    9: 5,\n",
    "    10: 4,\n",
    "    11: 11,\n",
    "    12: 12\n",
    "}\n",
    "train['월(중식)'] = train['월'].map(month_rank4lunch)\n",
    "test['월(중식)'] = test['월'].map(month_rank4lunch)\n",
    "\n",
    "weekday_rank4dinner = {\n",
    "    '월': 1,\n",
    "    '화': 2,\n",
    "    '수': 4,\n",
    "    '목': 3,\n",
    "    '금': 5,\n",
    "}\n",
    "\n",
    "weekday_rank4lunch = {\n",
    "    '월': 1,\n",
    "    '화': 2,\n",
    "    '수': 3,\n",
    "    '목': 4,\n",
    "    '금': 5,\n",
    "}\n",
    "\n",
    "train['요일(석식)'] = train['요일'].map(weekday_rank4dinner)\n",
    "test['요일(석식)'] = test['요일'].map(weekday_rank4dinner)\n",
    "\n",
    "train['요일(중식)'] = train['요일'].map(weekday_rank4lunch)\n",
    "test['요일(중식)'] = test['요일'].map(weekday_rank4lunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['조식메뉴', '중식메뉴', '석식메뉴'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 데이터 셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch_train = train.drop(columns=['일자', '요일', '월', '석식계', '요일(석식)', '월(석식)'])\n",
    "lunch_test = test.drop(columns=['일자', '요일', '월', '요일(석식)', '월(석식)', '조식메뉴', '중식메뉴', '석식메뉴'])\n",
    "\n",
    "\n",
    "dinner_train = train.drop(columns=['일자', '요일', '월', '중식계', '요일(중식)', '월(중식)'])\n",
    "dinner_test = test.drop(columns=['일자', '요일', '월', '요일(중식)', '월(중식)', '조식메뉴', '중식메뉴', '석식메뉴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lunch_train.shape)\n",
    "print(lunch_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dinner_train.shape)\n",
    "print(dinner_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분포 확인 및 분포 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_index = dinner_train[dinner_train['석식계']==0].index\n",
    "\n",
    "dinner_train.iloc[drop_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinner_train.drop(drop_index, inplace=True)\n",
    "\n",
    "print(dinner_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중식 예측모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lunch = np.array(lunch_train['중식계'])\n",
    "y_lunch = y_lunch.reshape(-1)\n",
    "lunch_train.drop(columns=['중식계'], inplace=True)\n",
    "\n",
    "y_dinner = np.array(dinner_train['석식계'])\n",
    "y_dinner = y_dinner.reshape(-1)\n",
    "dinner_train.drop(columns=['석식계'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [f for f in lunch_train.columns if lunch_train[f].dtype == 'object']\n",
    "\n",
    "def column_index(df, cat_features):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols, cat_features, sorter=sidx)]\n",
    "\n",
    "cat_features_idx = column_index(lunch_train, cat_features)    \n",
    "print(\"Cat features are: %s\" % [f for f in cat_features])\n",
    "print(cat_features_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "n_fold = 15\n",
    "\n",
    "kfold = KFold(n_splits=n_fold, shuffle=False)\n",
    "# for each fold\n",
    "\n",
    "lunch_models = [XGBRegressor(n_estimators = 3000, learning_rate = 0.1, loss_function='MAE') for _ in range(n_fold)]\n",
    "lunch_preds = []\n",
    "lunch_trues = []\n",
    "\n",
    "for idx, (tr_idx, val_idx) in enumerate(kfold.split(lunch_train, y_lunch)):\n",
    "    X_tr, X_val = lunch_train.iloc[tr_idx], lunch_train.iloc[val_idx]\n",
    "    y_tr, y_val = y_lunch[tr_idx], y_lunch[val_idx]\n",
    "\n",
    "    temp_model = lunch_models[idx]\n",
    "    temp_model.fit(X_tr, y_tr,\n",
    "                   eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "                   early_stopping_rounds= 50,\n",
    "#                    cat_features=cat_features,\n",
    "                   verbose=400)\n",
    "    \n",
    "    lunch_models[idx] = temp_model\n",
    "    \n",
    "    pred = temp_model.predict(X_val)\n",
    "    true = y_val\n",
    "    lunch_preds.extend(pred)\n",
    "    lunch_trues.extend(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(lunch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch = np.array([0]*50).astype(np.float64)\n",
    "\n",
    "for model in lunch_models:\n",
    "    lunch += model.predict(lunch_test)\n",
    "    \n",
    "lunch /= n_fold\n",
    "\n",
    "lunch_preds = np.array(lunch_preds)\n",
    "lunch_trues = np.array(lunch_trues)\n",
    "\n",
    "abs(lunch_trues-lunch_preds).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 석식 예측모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dinner_models = [CatBoostRegressor(n_estimators = 3000, learning_rate = 0.1, loss_function='MAE') for _ in range(n_fold)]\n",
    "dinner_preds = []\n",
    "dinner_trues = []\n",
    "\n",
    "for idx, (tr_idx, val_idx) in enumerate(kfold.split(dinner_train, y_dinner)):\n",
    "    X_tr, X_val = dinner_train.iloc[tr_idx, :-1], dinner_train.iloc[val_idx, :-1]\n",
    "    y_tr, y_val = y_dinner[tr_idx], y_dinner[val_idx]\n",
    "\n",
    "    temp_model = dinner_models[idx]\n",
    "    temp_model.fit(X_tr, y_tr,\n",
    "                   eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "                   early_stopping_rounds= 50,\n",
    "#                    cat_features=cat_features,\n",
    "                   verbose=400)\n",
    "    \n",
    "    dinner_models[idx] = temp_model\n",
    "    \n",
    "    pred = temp_model.predict(X_val)\n",
    "    true = y_val\n",
    "    dinner_preds.extend(pred)\n",
    "    dinner_trues.extend(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinner = np.array([0]*50).astype(np.float64)\n",
    "\n",
    "for model in dinner_models:\n",
    "    dinner += model.predict(dinner_test)\n",
    "    \n",
    "dinner /= n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinner_preds = np.array(dinner_preds)\n",
    "dinner_trues = np.array(dinner_trues)\n",
    "\n",
    "abs(dinner_preds - dinner_trues).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission.iloc[:,1] = lunch\n",
    "submission.iloc[:,2] = dinner\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv('../submission/20210628_cat_15_KJH.csv')\n",
    "\n",
    "lunch_answer = np.array(answer.iloc[:,1])\n",
    "dinner_answer = np.array(answer.iloc[:,2])\n",
    "\n",
    "abs(lunch - lunch_answer).mean(), abs(dinner - dinner_answer).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "today = str(datetime.datetime.now().date()).replace(\"-\",\"\")\n",
    "print(\"오늘 날짜 : \" + today)\n",
    "\n",
    "submission.to_csv(f'../submission/{today}_cat_15_.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names, model_type):\n",
    "    \n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_fold):\n",
    "    plot_feature_importance(dinner_models[0].get_feature_importance(),dinner_train.iloc[:,:-1].columns,\"CATBOOST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
