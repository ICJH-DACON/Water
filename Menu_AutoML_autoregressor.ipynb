{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'Gulim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workalendar.asia import SouthKorea\n",
    "import pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "- 일자에서 월과 일을 분리\n",
    "- 요일을 레이블 인코딩화(EDA로 요일의 중요도 순 파악)\n",
    "- 월 별, 일 별 중식 석식 수요 차이 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-b11c832c5082>:3: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  train['주'] = pd.DatetimeIndex(train['일자']).week\n",
      "<ipython-input-4-b11c832c5082>:4: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  test['주'] = pd.DatetimeIndex(test['일자']).week\n"
     ]
    }
   ],
   "source": [
    "train['월'] = pd.DatetimeIndex(train['일자']).month\n",
    "test['월'] = pd.DatetimeIndex(test['일자']).month\n",
    "train['주'] = pd.DatetimeIndex(train['일자']).week\n",
    "test['주'] = pd.DatetimeIndex(test['일자']).week\n",
    "train['일'] = pd.DatetimeIndex(train['일자']).day\n",
    "test['일'] = pd.DatetimeIndex(test['일자']).day\n",
    "\n",
    "train['출근'] = train['본사정원수']-(train['본사휴가자수']+train['본사출장자수']+train['현본사소속재택근무자수'])\n",
    "train['휴가비율'] = train['본사휴가자수']/train['본사정원수']\n",
    "train['출장비율'] = train['본사출장자수']/train['본사정원수']\n",
    "train['야근비율'] = train['본사시간외근무명령서승인건수']/train['출근']\n",
    "train['재택비율'] = train['현본사소속재택근무자수']/train['본사정원수']\n",
    "\n",
    "test['출근'] = test['본사정원수']-(test['본사휴가자수']+test['본사출장자수']+test['현본사소속재택근무자수'])\n",
    "test['휴가비율'] = test['본사휴가자수']/test['본사정원수']\n",
    "test['출장비율'] = test['본사출장자수']/test['본사정원수']\n",
    "test['야근비율'] = test['본사시간외근무명령서승인건수']/test['출근']\n",
    "test['재택비율'] = test['현본사소속재택근무자수']/test['본사정원수']\n",
    "\n",
    "train['식사가능자수'] = train['본사정원수'] - train['본사휴가자수'] - train['현본사소속재택근무자수']\n",
    "test['식사가능자수'] = test['본사정원수'] - test['본사휴가자수'] - test['현본사소속재택근무자수']\n",
    "\n",
    "# train['중식참여율'] = train['중식계'] / train['식사가능자수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_rank4dinner = {\n",
    "    1: 11,\n",
    "    2: 2,\n",
    "    3: 1,\n",
    "    4: 4,\n",
    "    5: 7,\n",
    "    6: 6,\n",
    "    7: 10,\n",
    "    8: 8,\n",
    "    9: 5,\n",
    "    10: 3,\n",
    "    11: 9,\n",
    "    12: 12\n",
    "}\n",
    "train['월(석식)'] = train['월'].map(month_rank4dinner)\n",
    "test['월(석식)'] = test['월'].map(month_rank4dinner)\n",
    "\n",
    "month_rank4lunch = {\n",
    "    1: 3,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 6,\n",
    "    5: 7,\n",
    "    6: 8,\n",
    "    7: 10,\n",
    "    8: 9,\n",
    "    9: 5,\n",
    "    10: 4,\n",
    "    11: 11,\n",
    "    12: 12\n",
    "}\n",
    "train['월(중식)'] = train['월'].map(month_rank4lunch)\n",
    "test['월(중식)'] = test['월'].map(month_rank4lunch)\n",
    "\n",
    "weekday_rank4dinner = {\n",
    "    '월': 1,\n",
    "    '화': 2,\n",
    "    '수': 4,\n",
    "    '목': 3,\n",
    "    '금': 5,\n",
    "}\n",
    "\n",
    "weekday_rank4lunch = {\n",
    "    '월': 1,\n",
    "    '화': 2,\n",
    "    '수': 3,\n",
    "    '목': 4,\n",
    "    '금': 5,\n",
    "}\n",
    "\n",
    "train['요일(석식)'] = train['요일'].map(weekday_rank4dinner)\n",
    "test['요일(석식)'] = test['요일'].map(weekday_rank4dinner)\n",
    "\n",
    "train['요일(중식)'] = train['요일'].map(weekday_rank4lunch)\n",
    "test['요일(중식)'] = test['요일'].map(weekday_rank4lunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rank = pd.DataFrame(range(1,53))\n",
    "week_rank_lunch = pd.pivot_table(train,values='중식계',index='주').sort_values(by='중식계').reset_index().drop('중식계',axis=1)\n",
    "week_rank_dinner = pd.pivot_table(train,values='석식계',index='주').sort_values(by='석식계').reset_index().drop('석식계',axis=1)\n",
    "\n",
    "\n",
    "week_rank4lunch = {}\n",
    "for i in range(len(rank)):\n",
    "    week_rank4lunch[week_rank_lunch['주'][i]] = rank[0][i]\n",
    "\n",
    "\n",
    "week_rank4dinner = {}\n",
    "for i in range(len(rank)):\n",
    "    week_rank4dinner[week_rank_dinner['주'][i]] = rank[0][i]\n",
    "    \n",
    "    \n",
    "train['주(중식)'] = train['주'].map(week_rank4lunch)\n",
    "test['주(중식)'] = test['주'].map(week_rank4lunch)\n",
    "\n",
    "train['주(석식)'] = train['주'].map(week_rank4dinner)\n",
    "test['주(석식)'] = test['주'].map(week_rank4dinner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_holiday(date):\n",
    "    holidays = list(map(str, pd.Series(np.array(SouthKorea().holidays(int(date[:4])))[:, 0])))\n",
    "    \n",
    "    yesterday = str(np.datetime64(date) - 1)\n",
    "    tomorrow = str(np.datetime64(date) + 1)\n",
    "\n",
    "    if tomorrow in holidays and yesterday in holidays:\n",
    "        return 3\n",
    "    if tomorrow in holidays:\n",
    "        return 2\n",
    "    elif yesterday in holidays:\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "\n",
    "def week_of_month(x):\n",
    "    dt = pendulum.parse(x)\n",
    "    \n",
    "    wom = dt.week_of_month\n",
    "    if wom < 0:\n",
    "        wom += 52\n",
    "    return wom\n",
    "    \n",
    "\n",
    "df = pd.concat([train[['본사정원수', '일자']], test[['본사정원수', '일자']]])\n",
    "df['년월'] = df['일자'].apply(lambda x : x[:7])\n",
    "df = df[['년월', '본사정원수']].groupby(by=['년월'], as_index=False).mean()\n",
    "\n",
    "def member_change(date):\n",
    "    this_month = date[:7]\n",
    "    last_month = str(np.datetime64(this_month) - 1)\n",
    "    \n",
    "    this_month_member = int(df[df['년월'] == this_month]['본사정원수'])\n",
    "    last_month_member = int(df[df['년월'] == last_month]['본사정원수'])\n",
    "    \n",
    "    \n",
    "    return  this_month_member - last_month_member\n",
    "\n",
    "train['공휴일전후'] = train['일자'].apply(is_holiday)\n",
    "test['공휴일전후'] = test['일자'].apply(is_holiday)\n",
    "\n",
    "train['몇주차'] = train['일자'].apply(week_of_month)\n",
    "test['몇주차'] = test['일자'].apply(week_of_month)\n",
    "\n",
    "train = train[train['일자'] > '2016-03']\n",
    "train['인원변화'] = train['일자'].apply(member_change)\n",
    "test['인원변화'] = test['일자'].apply(member_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공휴일 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['일자', '요일', '본사정원수', '본사휴가자수', '본사출장자수', '본사시간외근무명령서승인건수',\n",
       "       '현본사소속재택근무자수', '조식메뉴', '중식메뉴', '석식메뉴', '중식계', '석식계', '월', '주', '일',\n",
       "       '출근', '휴가비율', '출장비율', '야근비율', '재택비율', '식사가능자수', '월(석식)', '월(중식)',\n",
       "       '요일(석식)', '요일(중식)', '주(중식)', '주(석식)', '공휴일전후', '몇주차', '인원변화'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메뉴 변수 없이 사용할떄 해당 코드 사용['공휴일전후', '몇주차', '인원변화']\n",
    "\n",
    "lunch_train = train[['공휴일전후', '몇주차', '인원변화', '요일(중식)','월(중식)','일','주(중식)','출근', '휴가비율', '출장비율', '야근비율', '재택비율','본사출장자수','본사휴가자수','식사가능자수','본사시간외근무명령서승인건수']]\n",
    "lunch_test = test[['공휴일전후', '몇주차', '인원변화', '요일(중식)','월(중식)','일','주(중식)','출근', '휴가비율', '출장비율', '야근비율', '재택비율','본사출장자수','본사휴가자수','식사가능자수','본사시간외근무명령서승인건수']]\n",
    "\n",
    "dinner_train= train[['공휴일전후', '몇주차', '인원변화', '요일(석식)','월(석식)','일','주(석식)','출근', '휴가비율', '출장비율', '야근비율', '재택비율','본사출장자수','본사휴가자수','식사가능자수','본사시간외근무명령서승인건수']]\n",
    "dinner_test = test[['공휴일전후', '몇주차', '인원변화', '요일(석식)','월(석식)','일','주(석식)','출근', '휴가비율', '출장비율', '야근비율', '재택비율','본사출장자수','본사휴가자수','식사가능자수','본사시간외근무명령서승인건수']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['공휴일전후', '몇주차', '인원변화', '요일(중식)', '월(중식)', '일', '주(중식)', '출근', '휴가비율',\n",
       "       '출장비율', '야근비율', '재택비율', '본사출장자수', '본사휴가자수', '식사가능자수', '본사시간외근무명령서승인건수'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunch_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187, 16)\n",
      "(50, 16)\n"
     ]
    }
   ],
   "source": [
    "print(lunch_train.shape)\n",
    "print(lunch_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187, 16)\n",
      "(50, 16)\n"
     ]
    }
   ],
   "source": [
    "print(dinner_train.shape)\n",
    "print(dinner_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat features are: []\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cat_features = [f for f in lunch_train.columns if lunch_train[f].dtype == 'object']\n",
    "\n",
    "def column_index(df, cat_features):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols, cat_features, sorter=sidx)]\n",
    "\n",
    "cat_features_idx = column_index(lunch_train, cat_features)    \n",
    "print(\"Cat features are: %s\" % [f for f in cat_features])\n",
    "print(cat_features_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lunch = train[['중식계']]\n",
    "y_dinner = train[['석식계']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분포 확인 및 분포 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중식 예측모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl_alex import LightGBMRegressor, CatBoostRegressor, AutoMLRegressor\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m15:21:09\u001b[0m | \u001b[1m> Start Fit Base Model\u001b[0m\n",
      "\u001b[32m15:21:10\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:21:10\u001b[0m | \u001b[1m> Start Fit Models 2\u001b[0m\n",
      "\u001b[32m15:21:10\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:21:10\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:21:11\u001b[0m | \u001b[1m> Step 1: calc parameters and pruned score: get test 10 trials\u001b[0m\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m15:22:20\u001b[0m | \u001b[1m One iteration ~ 6.9 sec\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1m Possible iters ~ 140.0\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1m--------------------------------------------------\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1m  Pruned Threshold Score: 125.6322\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1m> Step 2: Full opt with Threshold Score Pruner\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1m> Start optimization with the parameters:\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1mCV_Folds = 12\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1mScore_CV_Folds = 3\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1mFeature_Selection = False\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1mOpt_lvl = 5\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1mCold_start = 15\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1mEarly_stoping = 120\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1mMetric = mean_absolute_error\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1mDirection = minimize\u001b[0m\n",
      "\u001b[32m15:22:21\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "Optimize: : 0it [00:00, ?it/s]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 1it [00:06,  6.80s/it, | Model: LightGBM | OptScore: 107.1606 | Best mean_absolute_error: 68.7503 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 2it [00:15,  7.65s/it, | Model: LightGBM | OptScore: 67.1373 | Best mean_absolute_error: 68.7503 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 3it [00:24,  8.50s/it, | Model: LightGBM | OptScore: 70.6103 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 4it [00:34,  9.03s/it, | Model: LightGBM | OptScore: 70.2008 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 5it [00:41,  8.50s/it, | Model: LightGBM | OptScore: 67.8983 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 6it [00:45,  6.98s/it, | Model: LightGBM | OptScore: 70.2734 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 7it [00:51,  6.48s/it, | Model: LightGBM | OptScore: 68.2322 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 8it [00:56,  6.01s/it, | Model: LightGBM | OptScore: 71.8031 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 9it [00:59,  4.98s/it, | Model: LightGBM | OptScore: 72.3595 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimize: : 10it [01:01,  4.27s/it, | Model: LightGBM | OptScore: 75.2383 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 11it [01:07,  4.80s/it, | Model: LightGBM | OptScore: 67.8451 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 12it [01:11,  4.43s/it, | Model: LightGBM | OptScore: 71.2995 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 13it [01:18,  5.17s/it, | Model: LightGBM | OptScore: 70.0908 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 14it [01:21,  4.49s/it, | Model: LightGBM | OptScore: 71.6398 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 15it [01:28,  5.39s/it, | Model: LightGBM | OptScore: 70.822 | Best mean_absolute_error: 67.1373 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 16it [01:32,  5.04s/it, | Model: LightGBM | OptScore: 68.9372 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 17it [01:36,  4.59s/it, | Model: LightGBM | OptScore: 68.0293 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 18it [01:41,  4.69s/it, | Model: LightGBM | OptScore: 77.9771 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 19it [01:45,  4.57s/it, | Model: LightGBM | OptScore: 67.5401 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 20it [01:49,  4.41s/it, | Model: LightGBM | OptScore: 68.799 | Best mean_absolute_error: 67.1373 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 21it [01:55,  4.82s/it, | Model: LightGBM | OptScore: 66.6818 | Best mean_absolute_error: 67.1373 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 22it [02:03,  5.75s/it, | Model: LightGBM | OptScore: 66.0397 | Best mean_absolute_error: 66.6818 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimize: : 23it [02:11,  6.55s/it, | Model: LightGBM | OptScore: 66.1953 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 24it [02:16,  5.86s/it, | Model: LightGBM | OptScore: 67.5828 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 25it [02:23,  6.22s/it, | Model: LightGBM | OptScore: 67.4464 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 26it [02:41,  9.75s/it, | Model: LightGBM | OptScore: 66.3718 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 27it [02:48,  9.18s/it, | Model: LightGBM | OptScore: 68.9796 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 28it [03:18, 15.16s/it, | Model: LightGBM | OptScore: 67.6379 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 29it [03:25, 12.88s/it, | Model: LightGBM | OptScore: 66.2963 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 30it [03:33, 11.50s/it, | Model: LightGBM | OptScore: 69.2932 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 31it [03:40, 10.07s/it, | Model: LightGBM | OptScore: 72.051 | Best mean_absolute_error: 66.0397 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 32it [04:00, 12.94s/it, | Model: LightGBM | OptScore: 67.674 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 33it [04:08, 11.38s/it, | Model: LightGBM | OptScore: 67.563 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 34it [04:15, 10.36s/it, | Model: LightGBM | OptScore: 70.2696 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 35it [04:24,  9.87s/it, | Model: LightGBM | OptScore: 68.4128 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 36it [04:36, 10.57s/it, | Model: LightGBM | OptScore: 67.966 | Best mean_absolute_error: 66.0397 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 37it [04:48, 10.75s/it, | Model: LightGBM | OptScore: 99.6954 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 38it [05:27, 19.36s/it, | Model: LightGBM | OptScore: 68.0304 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 39it [05:56, 22.22s/it, | Model: LightGBM | OptScore: 66.9703 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 40it [06:18, 22.11s/it, | Model: LightGBM | OptScore: 68.8677 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 41it [06:36, 20.83s/it, | Model: LightGBM | OptScore: 71.6564 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 42it [06:52, 19.37s/it, | Model: LightGBM | OptScore: 73.821 | Best mean_absolute_error: 66.0397 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 43it [07:22, 22.59s/it, | Model: LightGBM | OptScore: 70.0273 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 44it [07:26, 17.07s/it, | Model: LightGBM | OptScore: 75.3586 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 45it [07:37, 15.38s/it, | Model: LightGBM | OptScore: 72.3721 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 46it [07:48, 13.95s/it, | Model: LightGBM | OptScore: 66.2379 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimize: : 47it [07:59, 12.94s/it, | Model: LightGBM | OptScore: 66.5972 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 48it [08:08, 11.82s/it, | Model: LightGBM | OptScore: 66.4812 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 49it [08:16, 10.69s/it, | Model: LightGBM | OptScore: 66.2137 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 50it [08:23,  9.76s/it, | Model: LightGBM | OptScore: 67.4581 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 51it [08:30,  8.92s/it, | Model: LightGBM | OptScore: 64.5471 | Best mean_absolute_error: 66.0397 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 52it [08:35,  7.78s/it, | Model: LightGBM | OptScore: 110.3639 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 53it [08:39,  6.64s/it, | Model: LightGBM | OptScore: 67.9502 | Best mean_absolute_error: 64.5471 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 54it [08:53,  8.80s/it, | Model: LightGBM | OptScore: 66.5598 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 55it [08:57,  7.35s/it, | Model: LightGBM | OptScore: 73.8961 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 56it [09:04,  7.27s/it, | Model: LightGBM | OptScore: 66.5156 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 57it [09:10,  6.92s/it, | Model: LightGBM | OptScore: 67.9525 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 58it [09:21,  7.89s/it, | Model: LightGBM | OptScore: 66.9505 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 59it [09:28,  7.69s/it, | Model: LightGBM | OptScore: 67.2003 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 60it [09:35,  7.67s/it, | Model: LightGBM | OptScore: 66.0771 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimize: : 61it [09:48,  9.15s/it, | Model: LightGBM | OptScore: 65.1325 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 62it [10:02, 10.51s/it, | Model: LightGBM | OptScore: 68.7107 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 63it [10:16, 11.74s/it, | Model: LightGBM | OptScore: 66.1875 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 64it [10:29, 12.16s/it, | Model: LightGBM | OptScore: 67.7323 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 65it [10:45, 13.08s/it, | Model: LightGBM | OptScore: 67.0822 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 66it [10:59, 13.43s/it, | Model: LightGBM | OptScore: 65.0458 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 67it [11:13, 13.74s/it, | Model: LightGBM | OptScore: 64.861 | Best mean_absolute_error: 64.5471 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 68it [11:26, 13.42s/it, | Model: LightGBM | OptScore: 66.135 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 69it [11:42, 14.18s/it, | Model: LightGBM | OptScore: 64.5882 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 70it [11:58, 14.71s/it, | Model: LightGBM | OptScore: 64.7718 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 71it [12:11, 14.28s/it, | Model: LightGBM | OptScore: 118.455 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 72it [12:24, 13.73s/it, | Model: LightGBM | OptScore: 65.0835 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimize: : 73it [12:37, 13.65s/it, | Model: LightGBM | OptScore: 65.4009 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 74it [12:40, 10.53s/it, | Model: LightGBM | OptScore: 73.6381 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 75it [12:57, 12.37s/it, | Model: LightGBM | OptScore: 64.4765 | Best mean_absolute_error: 64.5471 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 76it [13:14, 13.67s/it, | Model: LightGBM | OptScore: 66.2856 | Best mean_absolute_error: 64.4765 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 77it [13:27, 13.59s/it, | Model: LightGBM | OptScore: 64.0312 | Best mean_absolute_error: 64.4765 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 78it [13:40, 13.50s/it, | Model: LightGBM | OptScore: 65.1873 | Best mean_absolute_error: 64.0312 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 79it [13:54, 10.56s/it, | Model: LightGBM | OptScore: 64.6907 | Best mean_absolute_error: 64.0312 ]\n",
      "\u001b[32m15:36:15\u001b[0m | \u001b[1m> Finish Opt!\u001b[0m\n",
      "\u001b[32m15:36:15\u001b[0m | \u001b[1mBest Score: 64.0312 mean_absolute_error\u001b[0m\n",
      "\u001b[32m15:36:15\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:36:15\u001b[0m | \u001b[1m> Fit Best Models\u001b[0m\n",
      "\u001b[32m15:36:15\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:37:03\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "\u001b[32m15:38:06\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "\u001b[32m15:38:32\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "\u001b[32m15:39:32\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "\u001b[32m15:40:22\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "\u001b[32m15:40:24\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:40:24\u001b[0m | \u001b[1m> Finish!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<automl_alex.automl_alex.AutoMLRegressor at 0x1f0aa510310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunch_model = AutoMLRegressor(random_state=42, metric=MAE)\n",
    "\n",
    "lunch_model.fit(lunch_train, y_lunch,\n",
    "                verbose=3,\n",
    "                folds=12,\n",
    "                opt_lvl=5,\n",
    "                early_stoping=120,\n",
    "                auto_parameters=False,\n",
    "                timeout=1100\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_Auto_lunch = lunch_model.predict(lunch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m15:40:34\u001b[0m | \u001b[1m> Start Fit Base Model\u001b[0m\n",
      "\u001b[32m15:40:36\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:40:36\u001b[0m | \u001b[1m> Start Fit Models 2\u001b[0m\n",
      "\u001b[32m15:40:36\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:40:36\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:40:36\u001b[0m | \u001b[1m> Step 1: calc parameters and pruned score: get test 10 trials\u001b[0m\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m One iteration ~ 7.3 sec\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m Possible iters ~ 134.0\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m--------------------------------------------------\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m  Pruned Threshold Score: 101.2066\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m> Step 2: Full opt with Threshold Score Pruner\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m> Start optimization with the parameters:\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1mCV_Folds = 12\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1mScore_CV_Folds = 3\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1mFeature_Selection = False\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1mOpt_lvl = 5\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1mCold_start = 15\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1mEarly_stoping = 120\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1mMetric = mean_absolute_error\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1mDirection = minimize\u001b[0m\n",
      "\u001b[32m15:41:49\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "Optimize: : 0it [00:00, ?it/s]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 1it [00:06,  6.99s/it, | Model: LightGBM | OptScore: 90.714 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 2it [00:15,  7.77s/it, | Model: LightGBM | OptScore: 62.4645 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 3it [00:25,  8.68s/it, | Model: LightGBM | OptScore: 62.3909 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 4it [00:34,  9.15s/it, | Model: LightGBM | OptScore: 75.8701 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 5it [01:18, 21.41s/it, | Model: LightGBM | OptScore: 63.719 | Best mean_absolute_error: 62.3574 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 6it [01:22, 15.62s/it, | Model: LightGBM | OptScore: 67.6026 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 7it [02:01, 23.32s/it, | Model: LightGBM | OptScore: 62.465 | Best mean_absolute_error: 62.3574 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 8it [02:04, 16.87s/it, | Model: LightGBM | OptScore: 65.7546 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 9it [02:15, 15.11s/it, | Model: LightGBM | OptScore: 69.9908 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 10it [02:20, 11.89s/it, | Model: LightGBM | OptScore: 69.7694 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 11it [02:33, 12.16s/it, | Model: LightGBM | OptScore: 62.7214 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 12it [02:49, 13.46s/it, | Model: LightGBM | OptScore: 63.4466 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 13it [03:17, 17.66s/it, | Model: LightGBM | OptScore: 62.7617 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 14it [03:19, 12.97s/it, | Model: LightGBM | OptScore: 68.0703 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 15it [03:30, 12.32s/it, | Model: LightGBM | OptScore: 63.8198 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 16it [03:49, 14.36s/it, | Model: LightGBM | OptScore: 69.2298 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 17it [03:53, 11.21s/it, | Model: LightGBM | OptScore: 107.9608 | Best mean_absolute_error: 62.3574 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 18it [04:24, 17.42s/it, | Model: LightGBM | OptScore: 62.1299 | Best mean_absolute_error: 62.3574 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 19it [04:49, 19.58s/it, | Model: LightGBM | OptScore: 62.8199 | Best mean_absolute_error: 62.1299 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 20it [05:06, 18.69s/it, | Model: LightGBM | OptScore: 63.9301 | Best mean_absolute_error: 62.1299 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 21it [05:11, 14.73s/it, | Model: LightGBM | OptScore: 64.8254 | Best mean_absolute_error: 62.1299 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 22it [05:36, 17.71s/it, | Model: LightGBM | OptScore: 101.8121 | Best mean_absolute_error: 62.1299 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimize: : 23it [06:14, 23.73s/it, | Model: LightGBM | OptScore: 62.8049 | Best mean_absolute_error: 62.1299 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 24it [06:28, 20.88s/it, | Model: LightGBM | OptScore: 63.5327 | Best mean_absolute_error: 62.1299 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 25it [06:36, 17.17s/it, | Model: LightGBM | OptScore: 105.5948 | Best mean_absolute_error: 62.1299 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "Optimize: : 26it [06:40, 13.11s/it, | Model: LightGBM | OptScore: 65.6841 | Best mean_absolute_error: 62.1299 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 27it [07:20, 21.25s/it, | Model: LightGBM | OptScore: 72.0418 | Best mean_absolute_error: 62.1299 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 28it [08:09, 29.45s/it, | Model: LightGBM | OptScore: 59.6484 | Best mean_absolute_error: 62.1299 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 29it [08:50, 33.01s/it, | Model: LightGBM | OptScore: 60.513 | Best mean_absolute_error: 59.6484 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 30it [09:36, 36.88s/it, | Model: LightGBM | OptScore: 62.5227 | Best mean_absolute_error: 59.6484 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 31it [10:14, 37.15s/it, | Model: LightGBM | OptScore: 59.6716 | Best mean_absolute_error: 59.6484 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 32it [10:50, 36.76s/it, | Model: LightGBM | OptScore: 61.0557 | Best mean_absolute_error: 59.6484 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 33it [11:18, 34.12s/it, | Model: LightGBM | OptScore: 59.3754 | Best mean_absolute_error: 59.6484 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 34it [11:40, 30.51s/it, | Model: LightGBM | OptScore: 66.0079 | Best mean_absolute_error: 59.3754 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 35it [12:11, 30.88s/it, | Model: LightGBM | OptScore: 58.769 | Best mean_absolute_error: 59.3754 ] C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 36it [12:34, 28.31s/it, | Model: LightGBM | OptScore: 59.3977 | Best mean_absolute_error: 58.769 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 37it [12:54, 25.95s/it, | Model: LightGBM | OptScore: 58.3782 | Best mean_absolute_error: 58.769 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 38it [13:16, 24.63s/it, | Model: LightGBM | OptScore: 58.2021 | Best mean_absolute_error: 58.3782 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 39it [13:37, 23.65s/it, | Model: LightGBM | OptScore: 58.3621 | Best mean_absolute_error: 58.2021 ]C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\optuna\\trial\\_trial.py:769: RuntimeWarning: Inconsistent parameter values for distribution with name \"lgbm_learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "Optimize: : 40it [13:59, 20.98s/it, | Model: LightGBM | OptScore: 58.1647 | Best mean_absolute_error: 58.2021 ]\n",
      "\u001b[32m15:55:48\u001b[0m | \u001b[1m> Finish Opt!\u001b[0m\n",
      "\u001b[32m15:55:48\u001b[0m | \u001b[1mBest Score: 58.1647 mean_absolute_error\u001b[0m\n",
      "\u001b[32m15:55:48\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m15:55:48\u001b[0m | \u001b[1m> Fit Best Models\u001b[0m\n",
      "\u001b[32m15:55:48\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m15:57:06\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m15:58:32\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m15:59:58\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m16:01:23\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "C:\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m16:03:33\u001b[0m | \u001b[1mSave DataPrepare\u001b[0m\n",
      "\u001b[32m16:03:38\u001b[0m | \u001b[1m##################################################\u001b[0m\n",
      "\u001b[32m16:03:38\u001b[0m | \u001b[1m> Finish!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<automl_alex.automl_alex.AutoMLRegressor at 0x1f0aa9d4490>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinner_model = AutoMLRegressor(random_state=42, metric=MAE)\n",
    "\n",
    "dinner_model.fit(dinner_train, y_dinner,         \n",
    "                 verbose=3,\n",
    "                 folds=12,\n",
    "                 opt_lvl=5,\n",
    "                 early_stoping=120,\n",
    "                 auto_parameters=False,\n",
    "                 timeout=1100\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['공휴일전후', '몇주차', '인원변화', '요일(중식)', '월(중식)', '일', '주(중식)', '출근', '휴가비율',\n",
       "        '출장비율', '야근비율', '재택비율', '본사출장자수', '본사휴가자수', '식사가능자수', '본사시간외근무명령서승인건수'],\n",
       "       dtype='object'),\n",
       " Index(['공휴일전후', '몇주차', '인원변화', '요일(중식)', '월(중식)', '일', '주(중식)', '출근', '휴가비율',\n",
       "        '출장비율', '야근비율', '재택비율', '본사출장자수', '본사휴가자수', '식사가능자수', '본사시간외근무명령서승인건수'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lunch_train.columns, lunch_test.columns, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_Auto_dinner = dinner_model.predict(dinner_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>중식계</th>\n",
       "      <th>석식계</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>987.876584</td>\n",
       "      <td>309.995352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>936.707541</td>\n",
       "      <td>414.287235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>620.741659</td>\n",
       "      <td>202.839631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>1290.781783</td>\n",
       "      <td>537.023116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>1084.047278</td>\n",
       "      <td>460.445252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           일자          중식계         석식계\n",
       "0  2021-01-27   987.876584  309.995352\n",
       "1  2021-01-28   936.707541  414.287235\n",
       "2  2021-01-29   620.741659  202.839631\n",
       "3  2021-02-01  1290.781783  537.023116\n",
       "4  2021-02-02  1084.047278  460.445252"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.iloc[:,1] = predicts_Auto_lunch\n",
    "submission.iloc[:,2] = predicts_Auto_dinner\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lunch_MAE :  19.060290110391904\n",
      "dinner_MAE :  16.000110031227837\n",
      "total_MAE :  17.53020007080987\n",
      "lunch_MAE :  58.67831945287493\n",
      "dinner_MAE :  37.069272300307965\n",
      "total_MAE :  47.873795876591444\n",
      "lunch_MAE :  14.955894937446146\n",
      "dinner_MAE :  10.091844176192525\n",
      "total_MAE :  12.523869556819335\n"
     ]
    }
   ],
   "source": [
    "def compare_ans(DIR):\n",
    "    answer = pd.read_csv(DIR)\n",
    "\n",
    "    lunch_answer = np.array(answer.iloc[:,1])\n",
    "    dinner_answer = np.array(answer.iloc[:,2])\n",
    "    \n",
    "    lunch_MAE = abs(predicts_Auto_lunch - lunch_answer).mean()\n",
    "    dinner_MAE = abs(predicts_Auto_dinner - dinner_answer).mean()\n",
    "    \n",
    "    print(\"lunch_MAE : \", lunch_MAE)\n",
    "    print(\"dinner_MAE : \", dinner_MAE)\n",
    "    print(\"total_MAE : \", (lunch_MAE+dinner_MAE)/2)\n",
    "    \n",
    "    \n",
    "compare_ans('../submission/20210701_lgbm_knfold_drop.csv')\n",
    "compare_ans('../submission/20210715_pycaret_(2).csv')\n",
    "compare_ans('../submission/20210715_lgbm_autoML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.539537282882215"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.cos(math.pi*68.44/180)*69.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 날짜 : 20210716\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.datetime.now().date()).replace(\"-\",\"\")\n",
    "print(\"오늘 날짜 : \" + today)\n",
    "\n",
    "submission.to_csv(f'../submission/{today}_lgbm_autoML.csv', index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv('../submission/20210715_pycaret_(2).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "best_submission.iloc[:,1:] = submission.iloc[:,1:]*5/9 +  answer.iloc[:,1:]*4/9\n",
    "best_submission.to_csv(f'../submission/{today}_lgbm_autoML_ensenble.csv', index =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
